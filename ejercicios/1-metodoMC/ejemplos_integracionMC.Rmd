---
title: "Integracion MC: Template"
output: html_document
---

## Settings
```{r settings}
rm(list = ls())
set.seed(050700)
unidad_de_tiempo <- "ms"
```

## Ejemplo: Integracion MC 1v
```{r}
rm(list = ls())
set.seed(050700)
unidad_de_tiempo <- "ms"

g <- function(x){
    (1 - x^2)^(3/2)
}
```


### MC directo
1) Generacion
```{r MC-directo}
genera_valor_aleatorio <- function(){
    runif(1, 0, 1) #generemos un valor en el interval [0,1]
}
```

2) Replicacion
```{r}
n <- 1e5

coste_directo <- bench::mark(
  {
    valores <- replicate(n, {
      x <- genera_valor_aleatorio()
      g(x)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_directo <- mean(valores)
varianza_directo <- var(valores) / n
eficiencia_directo <- 1 / (varianza_directo * coste_directo)
```

### MC Estratificado
1) Generacion
Pasos: 
- mirar la funcion
```{r }
library(ggplot2)

ggplot() +
  geom_function(fun = g) +
  xlim(0, 1)
```
- eligir los estratos
```{r}
estratos <- data.frame(
  min = c(0, 1 / 4),
  max = c(1 / 4, 1),
  probabilidad = c(1 / 4, 3 / 4)
)
```
- generacion
```{r generacion-estratificada}
genera_valor_aleatorio_en_estrato <- function(numero_estrato) {
  estrato <- estratos[numero_estrato, ]
  runif(1, min = estrato$min, max = estrato$max)
}
```

2) Replicacion
#### Asignacion proporcional
```{r}
n_estratos <- n * estratos$probabilidad
# Aseguramos valores enteros
n_estratos <- ceiling(n_estratos)
# Aseguramos al menos dos valores en cada estrato
n_estratos <- pmax(n_estratos, 2)

cantidad_estratos <- nrow(estratos)
coste_estratificado_proporcional <- bench::mark(
  {
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          x <- genera_valor_aleatorio_en_estrato(numero_estrato)
          g(x)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_estratificado_proporcional <- mean(unlist(valores))
varianza_estratificado_proporcional <- valores |>
  purrr::map_dbl(var) |>
  weighted.mean(w = estratos$probabilidad) |>
  magrittr::divide_by(n)
eficiencia_estratificado_proporcional <-
  1 / (varianza_estratificado_proporcional *
    coste_estratificado_proporcional)
```

#### Asignacion optima
```{r}
n_tanteo <- 100

coste_estratificado_optimo <- bench::mark(
  {
    # Estimación de las varianzas de los estratos
    n_estratos <- (n_tanteo * estratos$probabilidad) |>
      ceiling() |>
      pmax(2)
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          x <- genera_valor_aleatorio_en_estrato(numero_estrato)
          g(x)
        })
      }
    )

    # Cantidad óptima de valores en cada estrato
    sigmas <- purrr::map_dbl(valores, sd)
    n_estratos <-
      (n * estratos$probabilidad * sigmas /
        sum(estratos$probabilidad * sigmas)) |>
      ceiling() |>
      pmax(2)

    # Generación de valores en cada estrato
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          x <- genera_valor_aleatorio_en_estrato(numero_estrato)
          g(x)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_estratificado_optimo <- valores |>
  purrr::map_dbl(mean) |>
  weighted.mean(w = estratos$probabilidad)
varianza_estratificado_optimo <- valores |>
  purrr::map_dbl(sd) |>
  weighted.mean(w = estratos$probabilidad) |>
  magrittr::raise_to_power(2) |>
  magrittr::divide_by(n)
eficiencia_estratificado_optimo <-
  1 / (varianza_estratificado_optimo *
    coste_estratificado_optimo)
```



### MC por importancia
1) Generacion
- buscamos una distribucion instrumental
```{r}
alfa_instrumental <- 1
beta_instrumental <- 5 / 2

ggplot() +
  geom_function(fun = g, aes(colour = "g")) +
  geom_function(fun = dunif, aes(colour = "unif")) +
  geom_function(
    fun = dbeta,
    args = list(shape1 = alfa_instrumental, shape2 = beta_instrumental),
    aes(colour = "beta")
  ) +
  scale_colour_manual("",
    values = c(g = "black", unif = "blue", beta = "red"),
    breaks = c("g", "unif", "beta")
  ) +
  xlim(0, 1)
```
- generacion por importancia
```{r generacion-importancia}
genera_valor_aleatorio <- function() {
  rbeta(1, shape1 = alfa_instrumental, shape2 = beta_instrumental)
}

razon_de_verosimilitud <- function(x) {
  dunif(x) /
    dbeta(x, shape1 = alfa_instrumental, shape2 = beta_instrumental)
}

g_por_verosimilitud <- function(x) {
  g(x) * razon_de_verosimilitud(x)
}

# Haciendo uso de la simplificación matemática indicada antes, una
# implementación más eficiente para α=1 y β=5/2 sería
# g_por_verosimilitud <- function(x) {
#   (2 / 5) * (1 + x)^(3 / 2)
# }
```

2) Replicacion
```{r}
coste_importancia <- bench::mark(
  {
    valores <- replicate(n, {
      x <- genera_valor_aleatorio()
      g_por_verosimilitud(x)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_importancia <- mean(valores)
varianza_importancia <- var(valores) / n
eficiencia_importancia <-
  1 / (varianza_importancia * coste_importancia)
```


### Resultados
```{r tabla-de-resultados}
knitr::kable(
  data.frame(
    `Método` = c(
      "Directo",
      "Estratificado proporcional",
      "Estratificado óptimo",
      "Importancia"
    ),
    `Estimación` = c(
      estimacion_directo,
      estimacion_estratificado_proporcional,
      estimacion_estratificado_optimo,
      estimacion_importancia
    ),
    Varianza = c(
      varianza_directo,
      varianza_estratificado_proporcional,
      varianza_estratificado_optimo,
      varianza_importancia
    ),
    Coste = c(
      coste_directo,
      coste_estratificado_proporcional,
      coste_estratificado_optimo,
      coste_importancia
    ),
    Eficiencia = c(
      eficiencia_directo,
      eficiencia_estratificado_proporcional,
      eficiencia_estratificado_optimo,
      eficiencia_importancia
    )
  ),
  digits = 10
)
```

## Ejemplo: Integracion MC 2v
```{r}
rm(list = ls())
set.seed(050700)
unidad_de_tiempo <- "ms"
n <- 1e4
```

```{r}
g <- function(u) {
  u_1 <- u[[1]]
  u_2 <- u[[2]]
  5 * (5 * u_1 + 2)^2 * (3 * u_2 + 1)
}
```


### MC directo
1) Generacion
Generacion para MC directo
```{r MC-directo}
genera_vector_aleatorio <- function() {
  runif(n = 2)
}
```

2) Replicacion
```{r}
coste_directo <- bench::mark(
  {
    valores <- replicate(n, {
      u <- genera_vector_aleatorio()
      g(u)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_directo <- mean(valores)
varianza_directo <- var(valores) / n
eficiencia_directo <- 1 / (varianza_directo * coste_directo)
```

### MC estratificado

1) Generacion

Pasos: 
- generar los estratos
```{r}
genera_subintervalos <- function(numero_subintervalos) {
  extremos_derechos <-
    seq_len(numero_subintervalos) / numero_subintervalos
  extremos_izquierdos <-
    c(0, extremos_derechos[-numero_subintervalos])
  data.frame(
    min = extremos_izquierdos,
    max = extremos_derechos
  )
}

# Como en cada dimensión se va a considerar el mismo número de
# subintervalos, basta guardar la información una única vez
numero_subintervalos <- 5
subintervalos <- genera_subintervalos(numero_subintervalos)

# Los estratos vienen dados por todas las combinaciones posibles
estratos <- expand.grid(
  seq_len(numero_subintervalos),
  seq_len(numero_subintervalos)
)
cantidad_estratos <- nrow(estratos)
estratos$probabilidad <- 1 / cantidad_estratos
```

- generacion en los estratos
```{r generacion-estratificada}
genera_vector_aleatorio_en_estrato <- function(numero_estrato) {
  numero_estrato_u_1 <- estratos[numero_estrato, 1]
  numero_estrato_u_2 <- estratos[numero_estrato, 2]
  estrato_u_1 <- subintervalos[numero_estrato_u_1, ]
  estrato_u_2 <- subintervalos[numero_estrato_u_2, ]
  c(
    runif(1, min = estrato_u_1$min, max = estrato_u_1$max),
    runif(1, min = estrato_u_2$min, max = estrato_u_2$max)
  )
}
```

2) Replicacion

#### Asignacion proporcional
```{r}
n_estratos <- (n * estratos$probabilidad) |> 
  ceiling() |> 
  pmax(2)

coste_estratificado_proporcional <- bench::mark(
  {
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          u <- genera_vector_aleatorio_en_estrato(numero_estrato)
          g(u)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_estratificado_proporcional <- mean(unlist(valores))
varianza_estratificado_proporcional <- valores |> 
  purrr::map_dbl(var) |> 
  weighted.mean(w = estratos$probabilidad) |> 
  magrittr::divide_by(n)
eficiencia_estratificado_proporcional <-
  1 / (varianza_estratificado_proporcional *
    coste_estratificado_proporcional)
```

#### Asignacion optima
```{r}
n_tanteo <- 50 * cantidad_estratos

coste_estratificado_optimo <- bench::mark(
  {
    # Estimación de las varianzas de los estratos
    n_estratos <- (n_tanteo * estratos$probabilidad) |> 
      ceiling() |> 
      pmax(2)
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          u <- genera_vector_aleatorio_en_estrato(numero_estrato)
          g(u)
        })
      }
    )

    # Cantidad óptima de valores en cada estrato
    sigmas <- purrr::map_dbl(valores, sd)
    n_estratos <- 
      (n * estratos$probabilidad * sigmas /
         sum(estratos$probabilidad * sigmas)) |> 
      ceiling() |> 
      pmax(2)

    # Generación de valores en cada estrato
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          u <- genera_vector_aleatorio_en_estrato(numero_estrato)
          g(u)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_estratificado_optimo <- valores |> 
  purrr::map_dbl(mean) |> 
  weighted.mean(w = estratos$probabilidad)
varianza_estratificado_optimo <- valores |> 
  purrr::map_dbl(sd) |> 
  weighted.mean(w = estratos$probabilidad) |> 
  magrittr::raise_to_power(2) |> 
  magrittr::divide_by(n)
eficiencia_estratificado_optimo <-
  1 / (varianza_estratificado_optimo *
    coste_estratificado_optimo)
```


### MC por importancia 1
1) Generacion
- buscamos una distribucion instrumental
```{r}
alfa_instrumental_u_1 <- 3
beta_instrumental_u_1 <- 1
alfa_instrumental_u_2 <- 2
beta_instrumental_u_2 <- 1

densidad_nominal <- function(u) {
  u_1 <- u[[1]]
  u_2 <- u[[2]]
  dunif(u_1) * dunif(u_2)
}

densidad_instrumental <- function(u) {
  u_1 <- u[[1]]
  u_2 <- u[[2]]
  dbeta(u_1,
        shape1 = alfa_instrumental_u_1,
        shape2 = beta_instrumental_u_1) *
    dbeta(u_2,
          shape1 = alfa_instrumental_u_2,
          shape2 = beta_instrumental_u_2)
}

library(plotly)

malla <- data.frame(
  u_1 = seq_len(100) / 100,
  u_2 = seq_len(100) / 100
)

malla |> 
  plot_ly(x = ~u_1, y = ~u_2) |> 
  add_surface(z = outer(
    malla$u_1, malla$u_2,
    Vectorize(function(u_1, u_2) {
      u <- c(u_1, u_2)
      g(u) * densidad_nominal(u)
    })
  )) |> 
  add_surface(z = outer(
    malla$u_1, malla$u_2,
    Vectorize(function(u_1, u_2) {
      u <- c(u_1, u_2)
      densidad_instrumental(u)
    })
  ))
```
- revision grafica
```{r}
malla |> 
plot_ly(x = ~u_1, y = ~u_2) |> 
  add_surface(z = outer(
    malla$u_1, malla$u_2,
    Vectorize(function(u_1, u_2) {
      u <- c(u_1, u_2)
      g(u)
    })
  )) |> 
  add_surface(z = outer(
    malla$u_1, malla$u_2,
    Vectorize(function(u_1, u_2) {
      u <- c(u_1, u_2)
      densidad_nominal(u) / densidad_instrumental(u)
    })
  ))
```

- generacion por importancia
```{r generacion-importancia}
genera_vector_aleatorio <- function() {
  c(
    rbeta(1,
          shape1 = alfa_instrumental_u_1,
          shape2 = beta_instrumental_u_1),
    rbeta(1,
          shape1 = alfa_instrumental_u_2,
          shape2 = beta_instrumental_u_2)
  )
}

razon_de_verosimilitud <- function(u) {
  densidad_nominal(u) / densidad_instrumental(u)
}

g_por_verosimilitud <- function(u) {
  g(u) * razon_de_verosimilitud(u)
}

# Haciendo uso de la simplificación matemática indicada antes, una
# implementación más eficiente para α_u_1=3, β_u_1=1, α_u_2=2 y β_u_2=1 sería
# g_por_verosimilitud <- function(u) {
#   u_1 <- u[[1]]
#   u_2 <- u[[2]]
#   (5 / 6) * (5 + 2 / u_1)^2 * (3 + 1 / u_2)
# }
```


2) Replicacion
```{r}
coste_importancia_1 <- bench::mark(
  {
    valores <- replicate(n, {
      u <- genera_vector_aleatorio()
      g_por_verosimilitud(u)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r}
estimacion_importancia_1 <- mean(valores)
varianza_importancia_1 <- var(valores) / n
eficiencia_importancia_1 <-
  1 / (varianza_importancia_1 * coste_importancia_1)
```

### MC por importancia 2
1) Generacion
- perturbacion de la densidad nominal para cotar la razon de verosimilitud
(Recuerda que una densidad uniforme es una Beta(1,1))
```{r gráfica-verosimilitud-2}
alfa_instrumental_u_1 <- 1
beta_instrumental_u_1 <- 1 / 2
alfa_instrumental_u_2 <- 1
beta_instrumental_u_2 <- 1 / 2

densidad_instrumental <- function(u) {
  u_1 <- u[[1]]
  u_2 <- u[[2]]
  dbeta(u_1,
        shape1 = alfa_instrumental_u_1,
        shape2 = beta_instrumental_u_1) *
    dbeta(u_2,
          shape1 = alfa_instrumental_u_2,
          shape2 = beta_instrumental_u_2)
}

malla |> 
plot_ly(x = ~u_1, y = ~u_2) |> 
  add_surface(z = outer(
    malla$u_1, malla$u_2,
    Vectorize(function(u_1, u_2) {
      u <- c(u_1, u_2)
      densidad_nominal(u) / densidad_instrumental(u)
    })
  ))
```

- generacion
```{r generacion-importancia-2}
genera_vector_aleatorio <- function() {
  c(
    rbeta(1,
          shape1 = alfa_instrumental_u_1,
          shape2 = beta_instrumental_u_1),
    rbeta(1,
          shape1 = alfa_instrumental_u_2,
          shape2 = beta_instrumental_u_2)
  )
}

razon_de_verosimilitud <- function(u) {
  densidad_nominal(u) / densidad_instrumental(u)
}

g_por_verosimilitud <- function(u) {
  g(u) * razon_de_verosimilitud(u)
}

# Haciendo uso de la simplificación matemática indicada antes, una
# implementación más eficiente para α_u_1=1, β_u_1=1/2, α_u_2=1 y β_u_2=1/2 sería
# g_por_verosimilitud <- function(u) {
#   u_1 <- u[[1]]
#   u_2 <- u[[2]]
#   20 * (5 * u_1 + 2)^2 * (3 * u_2 + 1) * sqrt((1 - u_1) * (1 - u_2))
# }
```

2) Replicacion
```{r replicacion-importancia-2, warning=FALSE}
coste_importancia_2 <- bench::mark(
  {
    valores <- replicate(n, {
      u <- genera_vector_aleatorio()
      g_por_verosimilitud(u)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r estimacion-importancia-2}
estimacion_importancia_2 <- mean(valores)
varianza_importancia_2 <- var(valores) / n
eficiencia_importancia_2 <-
  1 / (varianza_importancia_2 * coste_importancia_2)
```


### MC por importancia 3

1) Generacion
Considerando una mixtura de la densidad nominal con la densidad deseada
```{r gráfica-verosimilitud-3}
alfa_instrumental_u_1 <- 3
beta_instrumental_u_1 <- 1
alfa_instrumental_u_2 <- 2
beta_instrumental_u_2 <- 1

densidad_instrumental <- function(u) {
  u_1 <- u[[1]]
  u_2 <- u[[2]]
  f_1 <- densidad_nominal(u)
  f_2 <-
    dbeta(u_1,
          shape1 = alfa_instrumental_u_1,
          shape2 = beta_instrumental_u_1) *
    dbeta(u_2,
          shape1 = alfa_instrumental_u_2,
          shape2 = beta_instrumental_u_2)
  0.7 * f_1 + 0.3 * f_2
}

malla |> 
plot_ly(x = ~u_1, y = ~u_2) |> 
  add_surface(z = outer(
    malla$u_1, malla$u_2,
    Vectorize(function(u_1, u_2) {
      u <- c(u_1, u_2)
      densidad_nominal(u) / densidad_instrumental(u)
    })
  ))
```

- generacion
```{r generacion-importancia-3}
genera_vector_aleatorio <- function() {
  if (runif(1) < 0.7) {
    runif(2)
  } else {
    c(
      rbeta(1,
            shape1 = alfa_instrumental_u_1,
            shape2 = beta_instrumental_u_1),
      rbeta(1,
            shape1 = alfa_instrumental_u_2,
            shape2 = beta_instrumental_u_2)
    )
  }
}

razon_de_verosimilitud <- function(u) {
  densidad_nominal(u) / densidad_instrumental(u)
}

g_por_verosimilitud <- function(u) {
  g(u) * razon_de_verosimilitud(u)
}
```

2) Replicacion
```{r replicacion-importancia-3, warning=FALSE}
coste_importancia_3 <- bench::mark(
  {
    valores <- replicate(n, {
      u <- genera_vector_aleatorio()
      g_por_verosimilitud(u)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

3) Estimacion
```{r estimacion-importancia-3}
estimacion_importancia_3 <- mean(valores)
varianza_importancia_3 <- var(valores) / n
eficiencia_importancia_3 <-
  1 / (varianza_importancia_3 * coste_importancia_3)
```



### Resultados
```{r tabla-de-resultados}
knitr::kable(
  data.frame(
    `Método` = c(
      "Directo",
      "Estratificado proporcional",
      "Estratificado óptimo",
      "Importancia 1"
    ),
    `Estimación` = c(
      estimacion_directo,
      estimacion_estratificado_proporcional,
      estimacion_estratificado_optimo,
      estimacion_importancia_1, 
      estimacion_importancia_2,
      estimacion_importancia_3
    ),
    Varianza = c(
      varianza_directo,
      varianza_estratificado_proporcional,
      varianza_estratificado_optimo,
      varianza_importancia_1,
      varianza_importancia_2,
      varianza_importancia_3
    ),
    Coste = c(
      coste_directo,
      coste_estratificado_proporcional,
      coste_estratificado_optimo,
      coste_importancia_1,
      coste_importancia_2,
      coste_importancia_3
    ),
    Eficiencia = c(
      eficiencia_directo,
      eficiencia_estratificado_proporcional,
      eficiencia_estratificado_optimo,
      eficiencia_importancia_1,
      eficiencia_importancia_2,
      eficiencia_importancia_3
    )
  ),
  digits = 10
)
```


