---
title: "Integración de Montecarlo (Integral unidimensional)"
output:
  html_document:
    theme:
      version: 4
---

```{r replicabilidad, include=FALSE}
set.seed(457367)
```

Consideremos la siguiente integral unidimensional:
\[
  I = \int_{0}^{1} (1 - x^{2})^{\frac{3}{2}} \mathop{}\!\mathrm{d} x
\]

A continuación vamos a estimar el valor de \( I \) mediante el método de Montecarlo, tanto de forma directa como usando distintas técnicas de reducción de varianza. Para poder comparar más fácilmente los resultados obtenidos, los recopilaremos en una tabla al final de este documento.

Para cada método estimaremos también su coste en tiempo haciendo uso de las herramientas proporcionadas por el paquete `bench` (en particular, la función `mark` analiza el coste en tiempo y en memoria de las expresiones proporcionadas, ejecutando cada una de ellas un cierto número de iteraciones y devolviendo una tabla con distintas medidas, entre ellas la mediana de los tiempos de ejecución de cada iteración). De esta forma, podremos comparar la eficiencia de cada método a la hora de estimar el valor de la integral. Para ello, es fundamental usar la misma unidad de tiempo a la hora de estimar el coste.

```{r configuración-bench}
unidad_de_tiempo <- "ms"
```


## Método directo de Montecarlo

```{r Montecarlo-directo, warning=FALSE}
genera_valor_aleatorio <- function() {
  runif(1)
}

g <- function(x) {
  (1 - x^2)^(3 / 2)
}

n <- 1e4
coste_directo <- bench::mark(
  {
    valores <- replicate(n, {
      x <- genera_valor_aleatorio()
      g(x)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median

estimacion_directo <- mean(valores)
varianza_directo <- var(valores) / n
eficiencia_directo <- 1 / (varianza_directo * coste_directo)
```


## Muestreo estratificado: asignación proporcional

La representación gráfica de la función \( g \) muestra que unos estratos adecuados podrían ser los subintervalos \( (0, 1/4) \) y \( (1/4, 1) \).

```{r grafica-g}
library(ggplot2)

ggplot() +
  geom_function(fun = g) +
  xlim(0, 1)
```

En primer lugar definimos los estratos y establecemos la forma de generar valores aleatorios dentro de cada estrato.

```{r generacion-estratificado}
estratos <- data.frame(
  min = c(0, 1 / 4),
  max = c(1 / 4, 1),
  probabilidad = c(1 / 4, 3 / 4)
)

genera_valor_aleatorio_en_estrato <- function(numero_estrato) {
  estrato <- estratos[numero_estrato, ]
  runif(1, min = estrato$min, max = estrato$max)
}
```

Ahora replicamos el proceso de generar valores en cada estrato, en una cantidad proporcional a su probabilidad, y aplicarles la función `g` a cada uno de ellos.

```{r replicacion-proporcional, warning=FALSE}
n_estratos <- n * estratos$probabilidad
# Aseguramos valores enteros
n_estratos <- ceiling(n_estratos)
# Aseguramos al menos dos valores en cada estrato
n_estratos <- pmax(n_estratos, 2)

cantidad_estratos <- nrow(estratos)
coste_estratificado_proporcional <- bench::mark(
  {
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          x <- genera_valor_aleatorio_en_estrato(numero_estrato)
          g(x)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

Las cantidades de valores generados en cada estrato son, respectivamente, `r pander::p(n_estratos, wrap="$", copula=" y ")`.

Finalmente, estimamos el valor de la integral, la varianza de esa estimación y la eficiencia del método.

```{r estimacion-proporcional}
estimacion_estratificado_proporcional <- mean(unlist(valores))
varianza_estratificado_proporcional <- valores |>
  purrr::map_dbl(var) |>
  weighted.mean(w = estratos$probabilidad) |>
  magrittr::divide_by(n)
eficiencia_estratificado_proporcional <-
  1 / (varianza_estratificado_proporcional *
    coste_estratificado_proporcional)
```


## Muestreo estratificado: asignación óptima

Consideramos los mismos estratos que antes y, por tanto, la misma forma de generar valores en cada uno de ellos.

Ahora replicamos el proceso de generar en cada estrato una cantidad óptima de valores, determinada mediante un procedimiento en dos etapas, y aplicarles la función `g` a cada uno de ellos. La estimación del coste en tiempo debe, por tanto, abarcar las dos etapas.

```{r replicacion-optimo, warning=FALSE}
n_tanteo <- 100

coste_estratificado_optimo <- bench::mark(
  {
    # Estimación de las varianzas de los estratos
    n_estratos <- (n_tanteo * estratos$probabilidad) |>
      ceiling() |>
      pmax(2)
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          x <- genera_valor_aleatorio_en_estrato(numero_estrato)
          g(x)
        })
      }
    )

    # Cantidad óptima de valores en cada estrato
    sigmas <- purrr::map_dbl(valores, sd)
    n_estratos <-
      (n * estratos$probabilidad * sigmas /
        sum(estratos$probabilidad * sigmas)) |>
      ceiling() |>
      pmax(2)

    # Generación de valores en cada estrato
    valores <- purrr::map2(
      seq_len(cantidad_estratos),
      n_estratos,
      \(numero_estrato, n_estrato) {
        replicate(n_estrato, {
          x <- genera_valor_aleatorio_en_estrato(numero_estrato)
          g(x)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

Las cantidades de valores generados en cada estrato son, respectivamente, `r pander::p(n_estratos, wrap="$", copula=" y ")`.

Finalmente, estimamos el valor de la integral, la varianza de esa estimación y la eficiencia del método.

```{r estimacion-optimo}
estimacion_estratificado_optimo <- valores |>
  purrr::map_dbl(mean) |>
  weighted.mean(w = estratos$probabilidad)
varianza_estratificado_optimo <- valores |>
  purrr::map_dbl(sd) |>
  weighted.mean(w = estratos$probabilidad) |>
  magrittr::raise_to_power(2) |>
  magrittr::divide_by(n)
eficiencia_estratificado_optimo <-
  1 / (varianza_estratificado_optimo *
    coste_estratificado_optimo)
```


## Muestreo por importancia

Buscamos una densidad instrumental con soporte al menos en el intervalo \( (0, 1) \) y que sea lo más parecida posible a la función \( |g(x)| f_{1}(x) \), donde \( f_{1} \) es la densidad de \( \mathrm{U}(0, 1) \). Puesto que la función de densidad de una distribución beta de parámetros \( \alpha \) y \( \beta \) es \( f_2(x) \propto x^{\alpha - 1} (1 - x)^{\beta - 1} \), con soporte en \( (0, 1) \), parece conveniente usar como densidad instrumental la de una distribución beta con \( \alpha = 1 \) y \( \beta = \frac{3}{2} + 1 = \frac{5}{2} \).

```{r densidad-instrumental}
alfa_instrumental <- 1
beta_instrumental <- 5 / 2

ggplot() +
  geom_function(fun = g, aes(colour = "g")) +
  geom_function(fun = dunif, aes(colour = "unif")) +
  geom_function(
    fun = dbeta,
    args = list(shape1 = alfa_instrumental, shape2 = beta_instrumental),
    aes(colour = "beta")
  ) +
  scale_colour_manual("",
    values = c(g = "black", unif = "blue", beta = "red"),
    breaks = c("g", "unif", "beta")
  ) +
  xlim(0, 1)
```

En primer lugar, establecemos la forma de generar valores aleatorios, que ahora será a partir de la distribución beta escogida. Por otra parte, el producto de \( g \) por la razón de verosimilitud (es decir, el cociente entre la función de densidad de la distribución uniforme y la función de densidad de la distribución beta escogida) es el siguiente:
\begin{equation*}
  g(x) \frac{1}{\frac{x^{1 - 1} (1 - x)^{5/2 - 1}}{B(1, 5/2)}}
  = B(1, 5/2) \Biggl( \frac{1 - x^{2}}{1 - x} \Biggr)^{3/2}
  = \frac{\Gamma(1) \Gamma(5/2)}{\Gamma(7/2)} (1 + x)^{3/2}
  = \frac{2}{5} (1 + x)^{3/2}
\end{equation*}
(en la primera igualdad se ha usado que \( B(\alpha, \beta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)} \) y en la última igualdad se han usado las propiedades \( \Gamma(1) = 1 \) y \( \Gamma(z + 1) = z\Gamma(z) \)).

```{r generacion-importancia}
genera_valor_aleatorio <- function() {
  rbeta(1, shape1 = alfa_instrumental, shape2 = beta_instrumental)
}

razon_de_verosimilitud <- function(x) {
  dunif(x) /
    dbeta(x, shape1 = alfa_instrumental, shape2 = beta_instrumental)
}

g_por_verosimilitud <- function(x) {
  g(x) * razon_de_verosimilitud(x)
}

# Haciendo uso de la simplificación matemática indicada antes, una
# implementación más eficiente para α=1 y β=5/2 sería
# g_por_verosimilitud <- function(x) {
#   (2 / 5) * (1 + x)^(3 / 2)
# }
```

Ahora replicamos el proceso de generar valores según la densidad instrumental y aplicarles la función `g_por_verosimilitud` a cada uno de ellos.

```{r replicacion-importancia, warning=FALSE}
coste_importancia <- bench::mark(
  {
    valores <- replicate(n, {
      x <- genera_valor_aleatorio()
      g_por_verosimilitud(x)
    })
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

Finalmente, estimamos el valor de la integral, la varianza de esa estimación y la eficiencia del método.

```{r estimacion-importancia}
estimacion_importancia <- mean(valores)
varianza_importancia <- var(valores) / n
eficiencia_importancia <-
  1 / (varianza_importancia * coste_importancia)
```


## Tabla comparativa de resultados

```{r tabla-de-resultados}
knitr::kable(
  data.frame(
    `Método` = c(
      "Directo",
      "Estratificado proporcional",
      "Estratificado óptimo",
      "Importancia"
    ),
    `Estimación` = c(
      estimacion_directo,
      estimacion_estratificado_proporcional,
      estimacion_estratificado_optimo,
      estimacion_importancia
    ),
    Varianza = c(
      varianza_directo,
      varianza_estratificado_proporcional,
      varianza_estratificado_optimo,
      varianza_importancia
    ),
    Coste = c(
      coste_directo,
      coste_estratificado_proporcional,
      coste_estratificado_optimo,
      coste_importancia
    ),
    Eficiencia = c(
      eficiencia_directo,
      eficiencia_estratificado_proporcional,
      eficiencia_estratificado_optimo,
      eficiencia_importancia
    )
  ),
  digits = 10
)
```

La tabla de resultados muestra que la eficiencia de la implementación realizada en este documento del método del muestreo estratificado es mucho menor que la del método directo, ya que la reducción de varianza conseguida es anulada completamente por el aumento del coste en tiempo. Sin embargo, para la implementación realizada del método del muestreo por importancia se puede observar cómo la varianza se reduce en un factor de \( 5 \), con solo un pequeño aumento del coste en tiempo. Esto quiere decir que, escogiendo una densidad instrumental adecuada, el método del muestreo por importancia es más eficiente que el método directo cuando se trata de estimar el valor de \( I \).
